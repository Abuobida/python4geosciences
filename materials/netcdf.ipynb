{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF files\n",
    "\n",
    "NetCDF is a binary storage format for many different kinds of rectangular data. Examples include atmosphere and ocean model output, satellite images, and timeseries data. NetCDF files are intended to be device independent, and the dataset may be queried in a fast, random-access way. More information about NetCDF files can be found [here](http://www.unidata.ucar.edu/software/netcdf/). The [CF conventions](http://cfconventions.org) are used for storing NetCDF data for earth system models, so that programs can be aware of the coordinate axes used by the data cubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cartopy\n",
    "import cmocean.cm as cmo\n",
    "\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sea surface temperature example\n",
    "\n",
    "An example NetCDF file containing monthly means of sea surface temperature over 160 years can be found [here](http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.ersst.v4.html). We'll use the NetCDF4 package to read this file, which has already been saved into the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc = netCDF4.Dataset('../data/sst.mnmean.v4.nc')\n",
    "print(nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of the object shows some of the attributes of the netCDF file. The final few lines show the dimensions and the variable names (with corresponding dimensions). Another representation of the file can be seen using the `ncdump` command. This is similar to the output of the command (at a command-line prompt, not within python) \n",
    "\n",
    "    $ ncdump -h ../data/sst.mnmean.v4.nc\n",
    "     \n",
    "    netcdf sst.mnmean.v4 {\n",
    "    dimensions:\n",
    "        lon = 180 ;\n",
    "        lat = 89 ;\n",
    "        nbnds = 2 ;\n",
    "        time = UNLIMITED ; // (1946 currently)\n",
    "    variables:\n",
    "        float lat(lat) ;\n",
    "            lat:units = \"degrees_north\" ;\n",
    "            lat:long_name = \"Latitude\" ;\n",
    "            lat:actual_range = 88.f, -88.f ;\n",
    "            lat:standard_name = \"latitude\" ;\n",
    "            lat:axis = \"Y\" ;\n",
    "            lat:coordinate_defines = \"center\" ;\n",
    "        float lon(lon) ;\n",
    "            lon:units = \"degrees_east\" ;\n",
    "            lon:long_name = \"Longitude\" ;\n",
    "            lon:actual_range = 0.f, 358.f ;\n",
    "            lon:standard_name = \"longitude\" ;\n",
    "            lon:axis = \"X\" ;\n",
    "            lon:coordinate_defines = \"center\" ;\n",
    "        double time_bnds(time, nbnds) ;\n",
    "            time_bnds:long_name = \"Time Boundaries\" ;\n",
    "        double time(time) ;\n",
    "            time:units = \"days since 1800-1-1 00:00:00\" ;\n",
    "            time:long_name = \"Time\" ;\n",
    "            time:delta_t = \"0000-01-00 00:00:00\" ;\n",
    "            time:avg_period = \"0000-01-00 00:00:00\" ;\n",
    "            time:prev_avg_period = \"0000-00-07 00:00:00\" ;\n",
    "            time:standard_name = \"time\" ;\n",
    "            time:axis = \"T\" ;\n",
    "            time:actual_range = 19723., 78923. ;\n",
    "        float sst(time, lat, lon) ;\n",
    "            sst:long_name = \"Monthly Means of Sea Surface Temperature\" ;\n",
    "            sst:units = \"degC\" ;\n",
    "            sst:var_desc = \"Sea Surface Temperature\" ;\n",
    "            sst:level_desc = \"Surface\" ;\n",
    "            sst:statistic = \"Mean\" ;\n",
    "            sst:missing_value = -9.96921e+36f ;\n",
    "            sst:actual_range = -1.8f, 33.95f ;\n",
    "            sst:valid_range = -5.f, 40.f ;\n",
    "            sst:dataset = \"NOAA Extended Reconstructed SST V4\" ;\n",
    "            sst:parent_stat = \"Individual Values\" ;\n",
    "\n",
    "    // global attributes:\n",
    "            :history = \"created 10/2014 by CAS using NCDC\\'s ERSST V4 ascii values\" ;\n",
    "    [....and so on....]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the netcdf object to the python object\n",
    "\n",
    "We can query the data within the NetCDF file using the NetCDF object. The structure of the object (the composition of the methods and attributes) is designed to mirror the data structure in the file. See how these queries give the same information as the textual representation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# `Global` attributes of the file\n",
    "nc.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variables are stored in a dictionary\n",
    "nc.variables['lon']  # this is a variable object, just a pointer to the variable. NO DATA HAS BEEN LOADED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable objects also have attributes\n",
    "nc.variables['lon'].units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can also query the dimensions\n",
    "nc.dimensions['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to find the length of a dimension, do\n",
    "len(nc.dimensions['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A list of the dimensions can be found by looking at the keys in the dimensions dictionary\n",
    "nc.dimensions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same for variables\n",
    "nc.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the main 3D variable\n",
    "nc['sst'] # A shorthand for nc.variables['sst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "> Inspect the NetCDF object. \n",
    "\n",
    ">  1. What are the units of the time variable?\n",
    ">  1. What are the dimensions of the latitude variable?\n",
    ">  1. What is the length of the latitude dimension?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can extract data from the file by indexing:\n",
    "lon = nc['lon'][:]\n",
    "lat = nc['lat'][:]\n",
    "sst = nc['sst'][0]   # same as nc['sst'][0, :, :], gets the first 2D time slice in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the time variable using the convenient num2date, which converts from time numbers to datetime objects\n",
    "time = netCDF4.num2date(nc['time'][:], nc['time'].units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Robinson(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.add_feature(cartopy.feature.LAND, facecolor='0.9')\n",
    "mappable = ax.contourf(lon, lat, sst, cmap=cmo.thermal, transform=cartopy.crs.PlateCarree())\n",
    "ax.set_title(time[0].isoformat())\n",
    "fig.colorbar(mappable).set_label(r'Sea Surface Temperature [$^\\circ$C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THREDDS example. Loading data from a remote dataset.\n",
    "\n",
    "The netCDF library can be compiled such that it is 'THREDDS enabled', which means that you can put in a URL instead of a filename. This allows access to large remote datasets, without having to download the entire file. You can find a large list of datasets served via an OpenDAP/THREDDs server [here](http://apdrc.soest.hawaii.edu/data/data.php).\n",
    "\n",
    "Let's look at the ESRL/NOAA 20th Century Reanalysis â€“ Version 2. You can access the data by the following link (this is the link of the `.dds` and `.das` files without the extension.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc_cprat = netCDF4.Dataset('http://apdrc.soest.hawaii.edu/dods/public_data/Reanalysis_Data/esrl/daily/monolevel/cprat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc_cprat['cprat'].long_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time = netCDF4.num2date(nc_cprat['time'][:], nc_cprat['time'].units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cprat = nc_cprat['cprat'][-1]   # get the last time, datetime.datetime(2012, 12, 31, 0, 0)\n",
    "lon = nc_cprat['lon'][:]\n",
    "lat = nc_cprat['lat'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Robinson(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.coastlines(linewidth=0.25)\n",
    "mappable = ax.contourf(lon, lat, cprat, 20, cmap=cmo.tempo, transform=cartopy.crs.PlateCarree())\n",
    "ax.set_title(time[-1].isoformat()[:10])\n",
    "fig.colorbar(mappable).set_label('%s' % nc_cprat['cprat'].long_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "> Pick another [variable](http://apdrc.soest.hawaii.edu/dods/public_data/Reanalysis_Data/esrl/daily/monolevel) from this dataset. Inspect and plot the variable in a similar manner to precipitation.\n",
    "\n",
    "> Find another dataset on a THREDDS server at SOEST (or elsewhere), pick a variable, and plot it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NetCDF files\n",
    "\n",
    "We can also create a NetCDF file to store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import tri\n",
    "\n",
    "Ndatapoints = 1000\n",
    "Ntimes = 20\n",
    "Nbad = 200\n",
    "\n",
    "xdata = np.random.rand(Ndatapoints)\n",
    "ydata = np.random.rand(Ndatapoints)\n",
    "time = np.arange(Ntimes)\n",
    "\n",
    "# create a progressive wave\n",
    "fdata = np.sin((xdata+ydata)[np.newaxis, :]*5.0 + \n",
    "               time[:, np.newaxis]/3.0)\n",
    "\n",
    "# remove some random 'bad' data.\n",
    "idx = range(fdata.size)\n",
    "np.random.shuffle(idx)\n",
    "fdata.flat[idx[:Nbad]] = np.nan\n",
    "\n",
    "ygrid, xgrid = np.mgrid[0:1:60j, 0:1:50j]\n",
    "fgrid = np.ma.empty((Ntimes, 60, 50), 'd')\n",
    "\n",
    "# interpolate\n",
    "for n in range(Ntimes):\n",
    "    igood = ~np.isnan(fdata[n])\n",
    "    t = tri.Triangulation(xdata[igood], ydata[igood])\n",
    "    interp = tri.LinearTriInterpolator(t, fdata[n][igood])\n",
    "    fgrid[n] = interp(xgrid, ygrid)\n",
    "\n",
    "# create netCDF file\n",
    "\n",
    "nc = netCDF4.Dataset('foo.nc', 'w')\n",
    "nc.author = 'Rob Hetland'\n",
    "\n",
    "nc.createDimension('x', 50)\n",
    "nc.createDimension('y', 60)\n",
    "nc.createDimension('time', None)    # An 'unlimited' dimension. \n",
    "\n",
    "nc.createVariable('f', 'd', ('time', 'y', 'x'))\n",
    "nc.variables['f'][:] = fgrid\n",
    "nc.variables['f'].units = 'meters sec-1'\n",
    "\n",
    "nc.createVariable('x', 'd', ('x',))\n",
    "nc.variables['x'][:] = xgrid[0, :]\n",
    "nc.variables['x'].units = 'meters'\n",
    "\n",
    "nc.createVariable('y', 'd', ('y',))\n",
    "nc.variables['y'][:] = ygrid[:, 0]\n",
    "nc.variables['y'].units = 'meters'\n",
    "\n",
    "nc.createVariable('time', 'd', ('time',))\n",
    "nc.variables['time'][:] = time\n",
    "nc.variables['time'].units = 'seconds'\n",
    "\n",
    "nc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRIB files\n",
    "\n",
    "NetCDF4 can also read GRIB2 files over THREDDS! GRIB files are used by NOAA for weather forecast and climate model output. There are many, many, many datasets that are available over THREDDS in GRIB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc = netCDF4.Dataset('http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cmd_grblow/2011/201103/20110301/spllnl.gdas.2011030118.grb2')\n",
    "sh = nc['Specific_humidity'][0, 0]\n",
    "lon = nc['lon'][:]\n",
    "lat = nc['lat'][:]\n",
    "time = netCDF4.num2date(nc['time'][0], nc['time'].units)\n",
    "\n",
    "proj = cartopy.crs.Robinson(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.coastlines(linewidth=0.25)\n",
    "mappable = ax.contourf(lon, lat, sh, 20, cmap=cmo.matter, transform=cartopy.crs.PlateCarree())\n",
    "plt.title(time.isoformat())\n",
    "fig.colorbar(mappable).set_label('%s' % nc['Specific_humidity'].long_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "> Find another dataset at [NOMADS](http://nomads.ncdc.noaa.gov/thredds) (or [here](http://nomads.ncdc.noaa.gov/data.php)), and plot it up!\n",
    "\n",
    "> *Bonus*: Try to read in and plot regional model predictions: [NAM](http://nomads.ncdc.noaa.gov/thredds/catalog/nam218/catalog.html)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See also\n",
    "\n",
    "- [Xarray](http://xarray.pydata.org/en/stable/): NetCDF + PANDAS + CF conventions. Awesome.\n",
    "- [pygrib](https://github.com/jswhit/pygrib): Reading GRIB files.\n",
    "- [ncview](http://meteora.ucsd.edu/~pierce/ncview_home_page.html): Not python, but a very useful NetCDF file viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `xarray`\n",
    "\n",
    "`xarray` expands the utility of the time series analysis package `pandas` into more than one dimension. It is actively being developed so some functionality isn't yet available, but for certain analysis it is very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous material, we used `netCDF` directly to read in a data file, then access the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc = netCDF4.Dataset('../data/sst.mnmean.v4.nc')\n",
    "\n",
    "print(nc['sst'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as was pointed out in class, in this approach if we want to pull out the sea surface temperature data at a particular time, we need to first know which time index that particular time corresponds to. How can we find this?\n",
    "\n",
    "First we convert the time numbers from the file into datetimes, like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the time variable using the convenient num2date\n",
    "time = netCDF4.num2date(nc['time'][:], nc['time'].units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to search for the time index corresponding to May 1, 1954."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime(1954, 5, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for the time index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tind = np.where(time==date)[0][0]\n",
    "print(tind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So the time index we want is 1204. We can now make our sea surface temperature plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Robinson(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.add_feature(cartopy.feature.LAND, facecolor='0.9')\n",
    "mappable = ax.contourf(nc['lon'][:], nc['lat'][:], nc['sst'][tind], cmap=cmo.thermal, transform=cartopy.crs.PlateCarree())\n",
    "ax.set_title(time[tind].isoformat())\n",
    "fig.colorbar(mappable).set_label(r'Sea Surface Temperature [$^\\circ$C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if instead we want the index corresponding to May 23, 1954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date = datetime(1954, 5, 23, 0, 0)\n",
    "np.where(time==date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem here? There is no data at that exact time.\n",
    "\n",
    "So what should we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "> Search for the time index corresponding to the time in the data file closest to May 23, 1954.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's access this data using a different package called `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/sst.mnmean.v4.nc')  # similar way to read in â€” also works for nonlocal data addresses\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can search for data in May 1954:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds['sst'].sel(time=slice('1954-05','1954-05'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can search for the nearest output to May 23, 1954:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds['sst'].sel(time='1954-05-23', method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sst = ds['sst'].sel(time='1954-05-23', method='nearest')\n",
    "\n",
    "proj = cartopy.crs.Robinson(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.add_feature(cartopy.feature.LAND, facecolor='0.9')\n",
    "mappable = ax.contourf(nc['lon'][:], nc['lat'][:], sst, cmap=cmo.thermal, transform=cartopy.crs.PlateCarree())\n",
    "ax.set_title(sst.time.data)\n",
    "fig.colorbar(mappable).set_label(r'Sea Surface Temperature [$^\\circ$C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also just plot against the included coordinates with built-in convenience functions (this is analogous to `pandas` which was for one dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sst.plot.contourf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy\n",
    "\n",
    "Like in `pandas`, we can use the `groupby` method to do some neat things. Let's group by season and save a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonal_mean = ds.groupby('time.season').mean('time')\n",
    "seasonal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember how many lines of code were required to save a netCDF file from scratch? It is straight-forward, but tedious. Once you are working with data using `xarray`, you can save new, derived files very easily from your data array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'output/test.nc'\n",
    "# seasonal_mean.to_netcdf(fname)  # you can't run this in read-only, but I already did for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = netCDF4.Dataset(fname)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Exercise*\n",
    "\n",
    "> Plot the difference between summer and winter mean sea surface temperature.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
